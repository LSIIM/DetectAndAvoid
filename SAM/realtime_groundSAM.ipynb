{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obv4v4E566lp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install + Import"
      ],
      "metadata": {
        "id": "57jJv-pA8Hjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.49.0"
      ],
      "metadata": {
        "id": "bkGGML_n7Vtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/zdata-inc/sam2_realtime\n",
        "%cd {HOME}/sam2_realtime\n",
        "!pip install -e . -q\n",
        "\n",
        "from sam2.build_sam import build_sam2_object_tracker\n",
        "\n",
        "%cd checkpoints\n",
        "!sh download_ckpts.sh\n",
        "%cd ..\n",
        "%cd ..\n"
      ],
      "metadata": {
        "id": "QcgsKLWJ7X13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autodistill-grounded-sam-2"
      ],
      "metadata": {
        "id": "sU_dtR-37r96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q supervision jupyter_bbox_widget\n"
      ],
      "metadata": {
        "id": "r_XCEUdP8BQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import urllib\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from IPython.display import clear_output, display\n",
        "from PIL import Image\n",
        "import supervision as sv"
      ],
      "metadata": {
        "id": "5hYcyD3_8UVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Visualizer:\n",
        "    def __init__(self,\n",
        "                 video_width,\n",
        "                 video_height,\n",
        "                 ):\n",
        "\n",
        "        self.video_width = video_width\n",
        "        self.video_height = video_height\n",
        "\n",
        "    def resize_mask(self, mask):\n",
        "        mask = torch.tensor(mask, device='cpu')\n",
        "        mask = torch.nn.functional.interpolate(mask,\n",
        "                                               size=(self.video_height, self.video_width),\n",
        "                                               mode=\"bilinear\",\n",
        "                                               align_corners=False,\n",
        "                                               )\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def add_frame(self, frame, mask):\n",
        "        frame = frame.copy()\n",
        "        frame = cv2.resize(frame, (self.video_width, self.video_height))\n",
        "\n",
        "        mask = self.resize_mask(mask=mask)\n",
        "        mask = (mask > 0.0).numpy()\n",
        "\n",
        "        colors = [[255, 20, 147], [255, 99, 71], [1, 255, 20], [255, 215, 0], [0, 226, 255], [255, 0, 43], [128, 128, 128], [0, 10, 64], [92, 247, 107], [221, 194, 255]]\n",
        "\n",
        "        for i in range(mask.shape[0]):\n",
        "            obj_mask = mask[i, 0, :, :]\n",
        "            frame[obj_mask] = colors[i]\n",
        "\n",
        "        rgb_frame = Image.fromarray(frame)\n",
        "        clear_output(wait=True)\n",
        "        display(rgb_frame)\n",
        "        img = np.array(rgb_frame)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        #print(rgb_frame)\n",
        "        return img"
      ],
      "metadata": {
        "id": "Z7A3mINt8avm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set SAM2 Configuration\n",
        "VIDEO_STREAM = f\"{HOME}/vid_dr03.mp4\"\n",
        "YOLO_CHECKPOINT_FILEPATH = \"yolov8x-seg.pt\"\n",
        "SAM_CHECKPOINT_FILEPATH = \"sam2_realtime/checkpoints/sam2.1_hiera_base_plus.pt\"\n",
        "SAM_CONFIG_FILEPATH = \"./configs/samurai/sam2.1_hiera_b+.yaml\"\n",
        "OUTPUT_PATH = VIDEO_STREAM + \"_segmented.mp4\"\n",
        "DEVICE = 'cuda'"
      ],
      "metadata": {
        "id": "XVltNJ4c8hJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open Video Stream\n",
        "video_stream = cv2.VideoCapture(VIDEO_STREAM)\n",
        "\n",
        "video_height = int(video_stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "video_width = int(video_stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "\n",
        "# For real-time visualization\n",
        "visualizer = Visualizer(video_width=video_width,\n",
        "                        video_height=video_height\n",
        "                        )"
      ],
      "metadata": {
        "id": "7xQ23Qqi8h5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autodistill_grounded_sam_2 import GroundedSAM2\n",
        "from autodistill.detection import CaptionOntology\n",
        "\n",
        "def tratar_first_frame(first_frame):\n",
        "\n",
        "  sky = f'sky'\n",
        "  sea = f'sea'\n",
        "  mountain = f'mountain'\n",
        "\n",
        "  base_model = GroundedSAM2(\n",
        "\tontology=CaptionOntology(\n",
        "    \t{\n",
        "        \t\"sky\": f\"{sky}\",\n",
        "          \"sea\": f\"{sea}\",\n",
        "          \"mountain\":f\"{mountain}\"\n",
        "\n",
        "    \t}\n",
        ")\n",
        ")\n",
        "\n",
        "  sky_mask = base_model.predict(first_frame)\n",
        "\n",
        "  NUM_OBJECTS = len(sky_mask.mask)\n",
        "\n",
        "  return sky_mask, NUM_OBJECTS"
      ],
      "metadata": {
        "id": "dMuBemDQ8lo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "available_slots = np.inf\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(f\"{HOME}/vid_dr03.mp4\")\n",
        "\n",
        "first_frame = True\n",
        "\n",
        "with sv.VideoSink(OUTPUT_PATH, video_info=video_info) as sink:\n",
        "  with torch.inference_mode(), torch.autocast('cuda', dtype=torch.bfloat16):\n",
        "      while video_stream.isOpened():\n",
        "\n",
        "          ret, frame = video_stream.read()\n",
        "\n",
        "\n",
        "          if not ret:\n",
        "              break\n",
        "\n",
        "          img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "          if first_frame:\n",
        "\n",
        "              ground_masks, n_obj = tratar_first_frame(img)\n",
        "\n",
        "              save_centers = []\n",
        "              save_temps = []\n",
        "\n",
        "              for mask_idx, mask_result in enumerate(ground_masks.mask):\n",
        "\n",
        "                x_min, y_min, x_max, y_max = ground_masks.xyxy[mask_idx]\n",
        "\n",
        "                temp = [[x_min, y_min], [x_max, y_max]]\n",
        "                save_temps.append(temp)\n",
        "\n",
        "                cx = int((x_min + x_max)/2)\n",
        "                cy = int((y_max + y_min)/2)\n",
        "                org = (cx, cy)\n",
        "                save_centers.append(org)\n",
        "\n",
        "              bbox = np.array(save_temps)\n",
        "\n",
        "              sam = build_sam2_object_tracker(num_objects=n_obj,\n",
        "                                config_file=SAM_CONFIG_FILEPATH,\n",
        "                                ckpt_path=SAM_CHECKPOINT_FILEPATH,\n",
        "                                device=DEVICE,\n",
        "                                verbose=False\n",
        "              )\n",
        "\n",
        "              sam_out = sam.track_new_object(img=img,\n",
        "                                            mask=ground_masks.mask\n",
        "                                            )\n",
        "\n",
        "              first_frame = False\n",
        "\n",
        "          else:\n",
        "\n",
        "              sam_out = sam.track_all_objects(img=img)\n",
        "\n",
        "\n",
        "          final = visualizer.add_frame(frame=frame, mask=sam_out['pred_masks'])\n",
        "\n",
        "          final = cv2.putText(final, 'sky', save_centers[0], cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                   1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "          final = cv2.putText(final, 'sea', save_centers[1], cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                   1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "          final = cv2.putText(final, 'mountain', save_centers[2], cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                   1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "          sink.write_frame(final)\n",
        "\n",
        "video_stream.release()"
      ],
      "metadata": {
        "id": "wNLjEO0g8tT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}